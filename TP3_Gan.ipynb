{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81c61c6-4b75-49f7-b7c8-b8ceb6963085",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#0d5874'> Inttroduction  au DCAGN (Deep Convolutional Generative Adversarial Network)\n",
    "    \n",
    "--- \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f69d9-5103-4b9a-941a-cf1949ec6a23",
   "metadata": {},
   "source": [
    "<span style='color:Red'>**L’objectif de cette séance de TP est d’illustrer par la pratique le fonctionnement des réseaux de neurones génératifs antagonistes (ou Generative Adversarial Networks, GAN) avec des couches de convolutions.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b440f71-3b07-4ebc-8632-54c38ac56f71",
   "metadata": {},
   "source": [
    "Le réseau générateur d'un DCGAN contient 4 couches cachées (nous traitons la couche d'entrée comme la 1ère couche cachée pour plus de simplicité) et 1 couche de sortie. Les couches de convolution transposées sont utilisées dans les couches cachées, qui sont suivies de couches de normalisation par lots et de fonctions d'activation ReLU. La couche de sortie est également une couche de convolution transposée et Tanh est utilisée comme fonction d'activation. L'architecture du générateur est représentée dans le schéma suivant :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4ed70-0a7e-43be-a455-cf9d788f4f2e",
   "metadata": {},
   "source": [
    "![Generateur.jpg](Generateur.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec16ea6-605d-4122-9497-df9c35b6712b",
   "metadata": {},
   "source": [
    "Les 2ème, 3ème et 4ème couches cachées et la couche de sortie ont une valeur de stride de 2. La 1ère couche a une valeur de padding de 0 et les autres couches ont une valeur de padding de 1. Comme la taille des images augmente de deux dans les couches plus profondes, le nombre de canaux diminue de moitié. Il s'agit d'une convention courante dans la conception de l'architecture des réseaux neuronaux. Toutes les tailles de noyau des couches de convolution transposées sont définies sur 4 x 4. Le canal de sortie peut être 1 ou 3, selon que vous souhaitez générer des images en niveaux de gris ou en couleurs. ou des images en couleur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d488052-22a8-40f2-a934-c1da165540f8",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834d0028-8f67-44c6-be31-824ac8b08473",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "DATA_PATH = '~/Data/mnist'\n",
    "OUT_PATH = 'output'\n",
    "LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNEL = 1\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 25\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8b956a-3604-4f42-80d4-dca75ef56ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e362c90-4d1a-430c-a432-59240a89fb09",
   "metadata": {},
   "source": [
    "Implémenter maintenant le réseau du générateur avec PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71255da9-7d48-4a33-9393-05df7d451140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            ###### Votre code ici ########\n",
    "            # 2nd layer\n",
    "            ###### Votre code ici ########\n",
    "            # 3rd layer\n",
    "            ###### Votre code ici ########\n",
    "            # 4th layer\n",
    "            ###### Votre code ici ########\n",
    "            # output layer\n",
    "            ###### Votre code ici ########\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6d296-293a-4eaa-98ca-70c4eb50aafa",
   "metadata": {},
   "source": [
    "Le réseau discriminant d'un DCGAN consiste en 4 couches cachées et 1 couche de sortie. Des couches de convolution sont utilisées dans toutes les couches, qui sont suivies de couches de normalisation par batch, sauf que la première couche n'a pas de normalisation par batch. Les fonctions d'activation LeakyReLU sont utilisées dans les couches cachées et la fonction Sigmoid est utilisée pour la couche de sortie. L'architecture du discriminateur est présentée dans le shéma suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f07316-f214-4b1c-b091-e25ceea4315a",
   "metadata": {},
   "source": [
    "![discrim.jpg](discrim.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac61a18-5549-4853-bb22-af2b70b08ea7",
   "metadata": {},
   "source": [
    "Le canal d'entrée peut être 1 ou 3, selon si les images sont en niveaux de gris ou en couleurs. Toutes les couches cachées ont une valeur de stride de 2 et une valeur de padding de 1 afin que la taille de leurs images de sortie soit égale à la moitié des images d'entrée. Comme la taille des images augmente dans les couches plus profondes, le nombre de canaux est multiplié par deux. Tous les noyaux des couches de convolution ont une taille de 4 x 4. La couche de sortie a une valeur de stride de 1 et une valeur de padding de 0. Elle mappe les cartes de caractéristiques 4 x 4 en valeurs uniques afin que la fonction Sigmoïde puisse transformer la valeur en confiance de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755a6f6-cfe7-4f67-a63e-db525aedd0ee",
   "metadata": {},
   "source": [
    "Implémenter maintenant le réseau du générateur avec PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efb0967-7d22-4ccd-9e9e-fde9129d59f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            ###### Votre code ici ########\n",
    "            # 2nd layer\n",
    "            ###### Votre code ici ########\n",
    "            # 3rd layer\n",
    "            ###### Votre code ici ########\n",
    "            # 4th layer\n",
    "            ###### Votre code ici ########\n",
    "            # output layer\n",
    "            ###### Votre code ici ########\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "    \n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63148786-3dbe-458a-9a5b-b2d9d4b74003",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c32be8-bb39-408a-afe5-24e8873faf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=DATA_PATH, download=True, transform=transforms.Compose([transforms.Resize(X_DIM),\n",
    "                                                                                  transforms.ToTensor(),\n",
    "                                                                                  transforms.Normalize((0.5,), (0.5,))\n",
    "                                                                                 ]))\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a052b-2f95-477f-99ef-dec47a3863c3",
   "metadata": {},
   "source": [
    "Implémenter maintenant le Gans sans fonction de validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913fc06a-46be-4092-ae53-21b7ab4fdcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0/469] loss_D_real: 0.3328 loss_D_fake: 1.5324 loss_G: 5.9021\n",
      "Epoch 0 [100/469] loss_D_real: 0.0116 loss_D_fake: 0.0059 loss_G: 7.7263\n",
      "Epoch 0 [200/469] loss_D_real: 0.0599 loss_D_fake: 0.1762 loss_G: 4.9483\n",
      "Epoch 0 [300/469] loss_D_real: 0.0278 loss_D_fake: 0.1385 loss_G: 4.7263\n",
      "Epoch 0 [400/469] loss_D_real: 0.3488 loss_D_fake: 0.0153 loss_G: 0.9172\n",
      "Epoch 1 [0/469] loss_D_real: 0.1619 loss_D_fake: 0.0614 loss_G: 2.7180\n",
      "Epoch 1 [100/469] loss_D_real: 0.1693 loss_D_fake: 0.4079 loss_G: 1.8593\n",
      "Epoch 1 [200/469] loss_D_real: 0.1228 loss_D_fake: 0.1377 loss_G: 2.5893\n",
      "Epoch 1 [300/469] loss_D_real: 0.2785 loss_D_fake: 0.0574 loss_G: 1.7871\n",
      "Epoch 1 [400/469] loss_D_real: 0.1320 loss_D_fake: 0.1623 loss_G: 2.3357\n",
      "Epoch 2 [0/469] loss_D_real: 0.0568 loss_D_fake: 0.3012 loss_G: 3.4725\n",
      "Epoch 2 [100/469] loss_D_real: 0.4887 loss_D_fake: 0.1665 loss_G: 1.6011\n",
      "Epoch 2 [200/469] loss_D_real: 0.0962 loss_D_fake: 0.8211 loss_G: 2.3223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MEHDIH~1\\AppData\\Local\\Temp/ipykernel_6160/2449658421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Update D with fake data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mz_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_DIM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss_D_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MEHDIH~1\\AppData\\Local\\Temp/ipykernel_6160/2984455155.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mnetG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    954\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    957\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x_real = data[0].to(device)\n",
    "        real_label = ###### Votre code ici ########\n",
    "        fake_label = ###### Votre code ici ########\n",
    "        # Update D with real data\n",
    "        netD.zero_grad()\n",
    "        y_real = ###### Votre code ici ######## \n",
    "        loss_D_real = ###### Votre code ici ########\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # Update D with fake data\n",
    "        z_noise = torch.randn(###### Votre code ici ########)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = ###### Votre code ici ########\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Update G with fake data\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = ###### Votre code ici ########\n",
    "        loss_G = ###### Votre code ici ########\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()  \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(epoch, i, len(dataloader), loss_D_real.mean().item(),\n",
    "                      loss_D_fake.mean().item(),\n",
    "                      loss_G.mean().item()\n",
    "                 ))\n",
    "            vutils.save_image(x_real, os.path.join(OUT_PATH,'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                vutils.save_image(viz_sample, os.path.join(OUT_PATH,'fake_samples_{}.png'.format(epoch)), normalize=True)\n",
    "            torch.save(netG.state_dict(), os.path.join(OUT_PATH,'netG_{}.pth'.format(epoch)))\n",
    "            torch.save(netD.state_dict(), os.path.join(OUT_PATH,'netD_{}.pth'.format(epoch)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa40cc-f060-47f3-8186-92281181aecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8095d-6074-4de5-8589-b24288e2cb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
